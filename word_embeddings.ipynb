{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gensim\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from topicViz.textinjupyter import markdown_scape_chars\n",
    "from topicViz.embedding import NLPProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/home/edgar/topic-visualization/data'\n",
    "model_path = f'{data_directory}/SO_vectors_200.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models already downloaded.\n"
     ]
    }
   ],
   "source": [
    "# download and load NLP model\n",
    "if not os.path.exists(model_path):\n",
    "    print('Downloading models...')\n",
    "    \n",
    "    !wget -O /home/edgar/topic-visualization/data/SO_vectors_200.bin https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1\n",
    "\n",
    "    print('Models downloaded.')\n",
    "\n",
    "else:\n",
    "\n",
    "    print('Models already downloaded.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    model_path,\n",
    "    binary=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/edgar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/edgar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# set resources for NLTK\n",
    "download('punkt')\n",
    "download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "html_clean_df = pd.read_csv(\n",
    "    \"data/html_cleaned.csv\",\n",
    "    index_col='Id',\n",
    ")\n",
    "\n",
    "text_html_clean_df = pd.read_csv(\n",
    "    \"data/text_html_cleaned.csv\",\n",
    "    index_col='Id',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "      <th>creationdate</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34552656</th>\n",
       "      <td>Java: Repeat Task Every Random Seconds</td>\n",
       "      <td>I'm already familiar with repeating tasks ever...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-01 00:21:59</td>\n",
       "      <td>LQ_CLOSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34553034</th>\n",
       "      <td>Why are Java Optionals immutable?</td>\n",
       "      <td>I'd like to understand why Java 8 Optionals we...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-01 02:03:20</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34553174</th>\n",
       "      <td>Text Overlay Image with Darkened Opacity React...</td>\n",
       "      <td>I am attempting to overlay a title over an ima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-01 02:48:24</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34553318</th>\n",
       "      <td>Why ternary operator in swift is so picky?</td>\n",
       "      <td>The question is very simple, but I just could ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-01 03:30:17</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34553755</th>\n",
       "      <td>hide/show fab with scale animation</td>\n",
       "      <td>I'm using custom floatingactionmenu. I need to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-01 05:21:48</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  \\\n",
       "Id                                                            \n",
       "34552656             Java: Repeat Task Every Random Seconds   \n",
       "34553034                  Why are Java Optionals immutable?   \n",
       "34553174  Text Overlay Image with Darkened Opacity React...   \n",
       "34553318         Why ternary operator in swift is so picky?   \n",
       "34553755                 hide/show fab with scale animation   \n",
       "\n",
       "                                                       body tags  \\\n",
       "Id                                                                 \n",
       "34552656  I'm already familiar with repeating tasks ever...  NaN   \n",
       "34553034  I'd like to understand why Java 8 Optionals we...  NaN   \n",
       "34553174  I am attempting to overlay a title over an ima...  NaN   \n",
       "34553318  The question is very simple, but I just could ...  NaN   \n",
       "34553755  I'm using custom floatingactionmenu. I need to...  NaN   \n",
       "\n",
       "                 creationdate         y  \n",
       "Id                                       \n",
       "34552656  2016-01-01 00:21:59  LQ_CLOSE  \n",
       "34553034  2016-01-01 02:03:20        HQ  \n",
       "34553174  2016-01-01 02:48:24        HQ  \n",
       "34553318  2016-01-01 03:30:17        HQ  \n",
       "34553755  2016-01-01 05:21:48        HQ  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_clean_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_processor = NLPProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text: title + body\n",
    "html_clean_df['post'] = (\n",
    "    html_clean_df['title'] + ' ' + html_clean_df['body']\n",
    ")\n",
    "\n",
    "text_html_clean_df['post'] = (\n",
    "    text_html_clean_df['title'] + ' ' + text_html_clean_df['body']\n",
    ")\n",
    "\n",
    "# drop nan values from post column\n",
    "html_clean_df.dropna(subset=['post'], inplace=True)\n",
    "text_html_clean_df.dropna(subset=['post'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "\"I need to know, is it possible to change some product's IP address using python scripts? If possible then how ? Includes Printer and other devices i am currently on some project. I just want to know if we have more than one products  and need to assign IP address to them **automatically** using python , is this possible. If yes please help me .\"\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "['I', 'need', 'to', 'know', ',', 'is', 'it', 'possible', 'to', 'change', 'some', 'product', \"'s\", 'IP', 'address', 'using', 'python', 'scripts', '?', 'If', 'possible', 'then', 'how', '?', 'Includes', 'Printer', 'and', 'other', 'devices', 'i', 'am', 'currently', 'on', 'some', 'project', '.', 'I', 'just', 'want', 'to', 'know', 'if', 'we', 'have', 'more', 'than', 'one', 'products', 'and', 'need', 'to', 'assign', 'IP', 'address', 'to', 'them', '*', '*', 'automatically', '*', '*', 'using', 'python', ',', 'is', 'this', 'possible', '.', 'If', 'yes', 'please', 'help', 'me', '.']\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "['I', 'need', 'know', ',', 'possible', 'change', 'product', \"'s\", 'IP', 'address', 'using', 'python', 'scripts', '?', 'If', 'possible', '?', 'Includes', 'Printer', 'devices', 'currently', 'project', '.', 'I', 'want', 'know', 'one', 'products', 'need', 'assign', 'IP', 'address', '*', '*', 'automatically', '*', '*', 'using', 'python', ',', 'possible', '.', 'If', 'yes', 'please', 'help', '.']\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "\"I need to know, is it possible to change some product's IP address using python scripts? If possible then how ? Includes Printer and other devices i am currently on some project  i just want to know if we have more than one products and need to assign ip address to them **automatically** using python   is this possible  if yes please help me  \"\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "['I', 'need', 'to', 'know', ',', 'is', 'it', 'possible', 'to', 'change', 'some', 'product', \"'s\", 'IP', 'address', 'using', 'python', 'scripts', '?', 'If', 'possible', 'then', 'how', '?', 'Includes', 'Printer', 'and', 'other', 'devices', 'i', 'am', 'currently', 'on', 'some', 'project', 'i', 'just', 'want', 'to', 'know', 'if', 'we', 'have', 'more', 'than', 'one', 'products', 'and', 'need', 'to', 'assign', 'ip', 'address', 'to', 'them', '*', '*', 'automatically', '*', '*', 'using', 'python', 'is', 'this', 'possible', 'if', 'yes', 'please', 'help', 'me']\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "['I', 'need', 'know', ',', 'possible', 'change', 'product', \"'s\", 'IP', 'address', 'using', 'python', 'scripts', '?', 'If', 'possible', '?', 'Includes', 'Printer', 'devices', 'currently', 'project', 'want', 'know', 'one', 'products', 'need', 'assign', 'ip', 'address', '*', '*', 'automatically', '*', '*', 'using', 'python', 'possible', 'yes', 'please', 'help']\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_row = 26052\n",
    "text_row = html_clean_df.iloc[n_row]['post']\n",
    "tokenized_row = nltk_processor.tokenize(text_row)\n",
    "no_stopwords_row = nltk_processor.remove_stopwords(\n",
    "    tokenized_text=tokenized_row,\n",
    "    stopwords=stop_words\n",
    ")\n",
    "\n",
    "markdown_scape_chars(text_row)\n",
    "print(len(tokenized_row))\n",
    "markdown_scape_chars(tokenized_row)\n",
    "print(len(no_stopwords_row))\n",
    "markdown_scape_chars(no_stopwords_row)\n",
    "\n",
    "print('#'*70)\n",
    "text_row = text_html_clean_df.iloc[n_row]['post']\n",
    "tokenized_row = nltk_processor.tokenize(text_row)\n",
    "no_stopwords_row = nltk_processor.remove_stopwords(\n",
    "    tokenized_text=tokenized_row,\n",
    "    stopwords=stop_words\n",
    ")\n",
    "\n",
    "markdown_scape_chars(text_row)\n",
    "print(len(tokenized_row))\n",
    "markdown_scape_chars(tokenized_row)\n",
    "print(len(no_stopwords_row))\n",
    "markdown_scape_chars(no_stopwords_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and remove stopwords from post column\n",
    "\n",
    "html_clean_df['tokenizedPost'] = html_clean_df['post'].apply(\n",
    "    nltk_processor.tokenize\n",
    ")\n",
    "\n",
    "html_clean_df['noStopWordsTokenizedPost'] = (\n",
    "    html_clean_df['tokenizedPost'].apply(\n",
    "        nltk_processor.remove_stopwords,\n",
    "        stopwords=stop_words\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_html_clean_df['tokenizedPost'] = (\n",
    "    text_html_clean_df['post'].apply(\n",
    "        nltk_processor.tokenize\n",
    "    )\n",
    ")\n",
    "\n",
    "text_html_clean_df['noSopWordsTokenizedPost'] = (\n",
    "    text_html_clean_df['tokenizedPost'].apply(\n",
    "        nltk_processor.remove_stopwords, stopwords=stop_words\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector representatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector representation of post column\n",
    "n_row = html_clean_df.shape[0]\n",
    "n_col = 200 # gensim model dimensionality\n",
    "\n",
    "embedding_html_clean = np.empty((n_row, n_col))\n",
    "embedding_text_html_clean = np.empty((n_row, n_col))\n",
    "\n",
    "embedding_html_clean = np.stack(\n",
    "    html_clean_df['noStopWordsTokenizedPost'].apply(\n",
    "        model.get_mean_vector,\n",
    "    )\n",
    ")\n",
    "np.save('data/embedding_html_clean.npy', embedding_html_clean)\n",
    "np.save(\n",
    "    'data/index_embedding_html_clean.npy',\n",
    "    html_clean_df.index.values\n",
    ")\n",
    "\n",
    "embedding_text_html_clean = np.stack(\n",
    "    text_html_clean_df['noSopWordsTokenizedPost'].apply(\n",
    "        model.get_mean_vector,\n",
    "    )\n",
    ")\n",
    "\n",
    "np.save(\n",
    "    'data/embedding_text_html_clean.npy',\n",
    "    embedding_text_html_clean\n",
    ")\n",
    "np.save(\n",
    "    'data/index_embedding_text_html_clean.npy',\n",
    "    text_html_clean_df.index.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
